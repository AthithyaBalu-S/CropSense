2024-11-07 23:07:10,220:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-07 23:07:10,223:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-07 23:07:10,223:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-07 23:07:10,223:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-07 23:07:21,117:INFO:PyCaret ClassificationExperiment
2024-11-07 23:07:21,117:INFO:Logging name: clf-default-name
2024-11-07 23:07:21,117:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-11-07 23:07:21,117:INFO:version 3.3.2
2024-11-07 23:07:21,117:INFO:Initializing setup()
2024-11-07 23:07:21,117:INFO:self.USI: 8518
2024-11-07 23:07:21,117:INFO:self._variable_keys: {'pipeline', 'y_train', 'fold_generator', 'logging_param', 'is_multiclass', 'log_plots_param', 'X_train', 'fix_imbalance', 'html_param', 'y_test', 'exp_name_log', 'USI', 'target_param', 'exp_id', 'seed', 'fold_shuffle_param', 'n_jobs_param', 'memory', 'idx', 'fold_groups_param', 'gpu_param', 'X', '_available_plots', 'gpu_n_jobs_param', 'y', '_ml_usecase', 'X_test', 'data'}
2024-11-07 23:07:21,117:INFO:Checking environment
2024-11-07 23:07:21,117:INFO:python_version: 3.10.12
2024-11-07 23:07:21,118:INFO:python_build: ('main', 'Sep 11 2024 15:47:36')
2024-11-07 23:07:21,118:INFO:machine: x86_64
2024-11-07 23:07:21,118:INFO:platform: Linux-6.1.85+-x86_64-with-glibc2.35
2024-11-07 23:07:21,118:INFO:Memory: svmem(total=13609422848, available=12053659648, percent=11.4, used=1219604480, free=6155669504, active=993865728, inactive=5976346624, buffers=531230720, cached=5702918144, shared=2768896, slab=377077760)
2024-11-07 23:07:21,126:INFO:Physical Core: 1
2024-11-07 23:07:21,126:INFO:Logical Core: 2
2024-11-07 23:07:21,126:INFO:Checking libraries
2024-11-07 23:07:21,126:INFO:System:
2024-11-07 23:07:21,126:INFO:    python: 3.10.12 (main, Sep 11 2024, 15:47:36) [GCC 11.4.0]
2024-11-07 23:07:21,126:INFO:executable: /usr/bin/python3
2024-11-07 23:07:21,126:INFO:   machine: Linux-6.1.85+-x86_64-with-glibc2.35
2024-11-07 23:07:21,127:INFO:PyCaret required dependencies:
2024-11-07 23:07:24,673:WARNING:/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-11-07 23:07:25,409:INFO:                 pip: 24.1.2
2024-11-07 23:07:25,409:INFO:          setuptools: 75.1.0
2024-11-07 23:07:25,409:INFO:             pycaret: 3.3.2
2024-11-07 23:07:25,409:INFO:             IPython: 7.34.0
2024-11-07 23:07:25,409:INFO:          ipywidgets: 7.7.1
2024-11-07 23:07:25,409:INFO:                tqdm: 4.66.6
2024-11-07 23:07:25,409:INFO:               numpy: 1.26.4
2024-11-07 23:07:25,409:INFO:              pandas: 2.1.4
2024-11-07 23:07:25,409:INFO:              jinja2: 3.1.4
2024-11-07 23:07:25,409:INFO:               scipy: 1.11.4
2024-11-07 23:07:25,409:INFO:              joblib: 1.3.2
2024-11-07 23:07:25,409:INFO:             sklearn: 1.4.2
2024-11-07 23:07:25,409:INFO:                pyod: 2.0.2
2024-11-07 23:07:25,410:INFO:            imblearn: 0.12.4
2024-11-07 23:07:25,410:INFO:   category_encoders: 2.6.4
2024-11-07 23:07:25,410:INFO:            lightgbm: 4.5.0
2024-11-07 23:07:25,410:INFO:               numba: 0.60.0
2024-11-07 23:07:25,410:INFO:            requests: 2.32.3
2024-11-07 23:07:25,410:INFO:          matplotlib: 3.7.5
2024-11-07 23:07:25,410:INFO:          scikitplot: 0.3.7
2024-11-07 23:07:25,410:INFO:         yellowbrick: 1.5
2024-11-07 23:07:25,410:INFO:              plotly: 5.24.1
2024-11-07 23:07:25,410:INFO:    plotly-resampler: Not installed
2024-11-07 23:07:25,410:INFO:             kaleido: 0.2.1
2024-11-07 23:07:25,410:INFO:           schemdraw: 0.15
2024-11-07 23:07:25,410:INFO:         statsmodels: 0.14.4
2024-11-07 23:07:25,410:INFO:              sktime: 0.26.0
2024-11-07 23:07:25,410:INFO:               tbats: 1.1.3
2024-11-07 23:07:25,410:INFO:            pmdarima: 2.0.4
2024-11-07 23:07:25,410:INFO:              psutil: 5.9.5
2024-11-07 23:07:25,410:INFO:          markupsafe: 3.0.2
2024-11-07 23:07:25,410:INFO:             pickle5: Not installed
2024-11-07 23:07:25,410:INFO:         cloudpickle: 3.1.0
2024-11-07 23:07:25,410:INFO:         deprecation: 2.1.0
2024-11-07 23:07:25,411:INFO:              xxhash: 3.5.0
2024-11-07 23:07:25,411:INFO:           wurlitzer: 3.1.1
2024-11-07 23:07:25,411:INFO:PyCaret optional dependencies:
2024-11-07 23:07:26,029:INFO:                shap: 0.46.0
2024-11-07 23:07:26,029:INFO:           interpret: Not installed
2024-11-07 23:07:26,029:INFO:                umap: Not installed
2024-11-07 23:07:26,029:INFO:     ydata_profiling: Not installed
2024-11-07 23:07:26,030:INFO:  explainerdashboard: Not installed
2024-11-07 23:07:26,030:INFO:             autoviz: Not installed
2024-11-07 23:07:26,030:INFO:           fairlearn: Not installed
2024-11-07 23:07:26,030:INFO:          deepchecks: Not installed
2024-11-07 23:07:26,030:INFO:             xgboost: 2.1.2
2024-11-07 23:07:26,030:INFO:            catboost: Not installed
2024-11-07 23:07:26,030:INFO:              kmodes: Not installed
2024-11-07 23:07:26,030:INFO:             mlxtend: 0.23.1
2024-11-07 23:07:26,030:INFO:       statsforecast: Not installed
2024-11-07 23:07:26,030:INFO:        tune_sklearn: Not installed
2024-11-07 23:07:26,030:INFO:                 ray: Not installed
2024-11-07 23:07:26,030:INFO:            hyperopt: 0.2.7
2024-11-07 23:07:26,030:INFO:              optuna: Not installed
2024-11-07 23:07:26,030:INFO:               skopt: Not installed
2024-11-07 23:07:26,030:INFO:              mlflow: Not installed
2024-11-07 23:07:26,030:INFO:              gradio: Not installed
2024-11-07 23:07:26,030:INFO:             fastapi: Not installed
2024-11-07 23:07:26,030:INFO:             uvicorn: Not installed
2024-11-07 23:07:26,030:INFO:              m2cgen: Not installed
2024-11-07 23:07:26,030:INFO:           evidently: Not installed
2024-11-07 23:07:26,030:INFO:               fugue: Not installed
2024-11-07 23:07:26,031:INFO:           streamlit: Not installed
2024-11-07 23:07:26,031:INFO:             prophet: 1.1.6
2024-11-07 23:07:26,031:INFO:None
2024-11-07 23:07:26,031:INFO:Set up data.
2024-11-07 23:07:26,045:INFO:Set up folding strategy.
2024-11-07 23:07:26,045:INFO:Set up train/test split.
2024-11-07 23:07:26,064:INFO:Set up index.
2024-11-07 23:07:26,065:INFO:Assigning column types.
2024-11-07 23:07:26,074:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-07 23:07:26,170:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-07 23:07:26,176:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-07 23:07:26,249:INFO:Soft dependency imported: xgboost: 2.1.2
2024-11-07 23:07:26,254:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-07 23:07:26,340:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-07 23:07:26,342:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-07 23:07:26,405:INFO:Soft dependency imported: xgboost: 2.1.2
2024-11-07 23:07:26,411:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-07 23:07:26,412:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-07 23:07:26,503:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-07 23:07:26,563:INFO:Soft dependency imported: xgboost: 2.1.2
2024-11-07 23:07:26,568:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-07 23:07:26,657:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-07 23:07:26,717:INFO:Soft dependency imported: xgboost: 2.1.2
2024-11-07 23:07:26,722:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-07 23:07:26,722:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-11-07 23:07:26,952:INFO:Soft dependency imported: xgboost: 2.1.2
2024-11-07 23:07:26,957:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-07 23:07:27,145:INFO:Soft dependency imported: xgboost: 2.1.2
2024-11-07 23:07:27,163:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-07 23:07:27,174:INFO:Preparing preprocessing pipeline...
2024-11-07 23:07:27,181:INFO:Set up label encoding.
2024-11-07 23:07:27,181:INFO:Set up simple imputation.
2024-11-07 23:07:27,198:INFO:Set up encoding of categorical features.
2024-11-07 23:07:27,343:INFO:Finished creating preprocessing pipeline.
2024-11-07 23:07:27,356:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=['Yield'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              str...
                                                              strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Nitrogen', 'Phosphorus',
                                             'Potassium', 'Temperature',
                                             'Humidity', 'pH_Value',
                                             'Rainfall'],
                                    transformer=TargetEncoder(cols=[],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2024-11-07 23:07:27,356:INFO:Creating final display dataframe.
2024-11-07 23:07:27,871:INFO:Setup _display_container:                     Description  \
0                    Session id   
1                        Target   
2                   Target type   
3                Target mapping   
4           Original data shape   
5        Transformed data shape   
6   Transformed train set shape   
7    Transformed test set shape   
8              Numeric features   
9          Categorical features   
10                   Preprocess   
11              Imputation type   
12           Numeric imputation   
13       Categorical imputation   
14     Maximum one-hot encoding   
15              Encoding method   
16               Fold Generator   
17                  Fold Number   
18                     CPU Jobs   
19                      Use GPU   
20               Log Experiment   
21              Experiment Name   
22                          USI   

                                                Value  
0                                                3814  
1                                                Crop  
2                                          Multiclass  
3   Apple: 0, Banana: 1, Blackgram: 2, ChickPea: 3...  
4                                           (2200, 9)  
5                                           (2200, 9)  
6                                           (1540, 9)  
7                                            (660, 9)  
8                                                   1  
9                                                   7  
10                                               True  
11                                             simple  
12                                               mean  
13                                               mode  
14                                                 25  
15                                               None  
16                                    StratifiedKFold  
17                                                 10  
18                                                 -1  
19                                              False  
20                                              False  
21                                   clf-default-name  
22                                               8518  
2024-11-07 23:07:28,089:INFO:Soft dependency imported: xgboost: 2.1.2
2024-11-07 23:07:28,093:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-07 23:07:28,281:INFO:Soft dependency imported: xgboost: 2.1.2
2024-11-07 23:07:28,292:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-07 23:07:28,295:INFO:setup() successfully completed in 7.19s...............
2024-11-07 23:07:32,238:INFO:Initializing compare_models()
2024-11-07 23:07:32,238:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x787230167fd0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x787230167fd0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-11-07 23:07:32,238:INFO:Checking exceptions
2024-11-07 23:07:32,249:INFO:Preparing display monitor
2024-11-07 23:07:32,338:INFO:Initializing Logistic Regression
2024-11-07 23:07:32,338:INFO:Total runtime is 3.6597251892089843e-06 minutes
2024-11-07 23:07:32,349:INFO:SubProcess create_model() called ==================================
2024-11-07 23:07:32,350:INFO:Initializing create_model()
2024-11-07 23:07:32,350:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x787230167fd0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x78723019c5e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-07 23:07:32,350:INFO:Checking exceptions
2024-11-07 23:07:32,350:INFO:Importing libraries
2024-11-07 23:07:32,350:INFO:Copying training dataset
2024-11-07 23:07:32,360:INFO:Defining folds
2024-11-07 23:07:32,360:INFO:Declaring metric variables
2024-11-07 23:07:32,369:INFO:Importing untrained model
2024-11-07 23:07:32,381:INFO:Logistic Regression Imported successfully
2024-11-07 23:07:32,405:INFO:Starting cross validation
2024-11-07 23:07:32,409:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-07 23:07:39,333:WARNING:/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-11-07 23:07:39,352:WARNING:/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-11-07 23:07:41,361:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-07 23:07:41,402:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:07:41,407:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:41,417:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:41,424:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:41,425:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-07 23:07:41,468:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:07:41,474:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:41,482:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:41,490:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:43,224:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-07 23:07:43,291:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:07:43,294:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:43,298:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-07 23:07:43,301:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:43,308:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:43,334:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:07:43,337:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:43,344:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:43,351:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:44,972:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-07 23:07:45,008:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:07:45,012:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:45,021:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:45,022:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-07 23:07:45,028:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:45,060:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:07:45,064:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:45,071:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:45,079:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:46,781:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-07 23:07:46,813:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-07 23:07:46,816:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:07:46,820:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:46,827:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:46,834:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:46,848:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:07:46,851:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:46,858:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:46,865:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:49,046:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-07 23:07:49,079:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:07:49,082:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:49,088:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:49,098:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:49,214:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-07 23:07:49,246:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:07:49,250:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:49,256:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:49,263:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:49,283:INFO:Calculating mean and std
2024-11-07 23:07:49,293:INFO:Creating metrics dataframe
2024-11-07 23:07:49,298:INFO:Uploading results into container
2024-11-07 23:07:49,299:INFO:Uploading model into container now
2024-11-07 23:07:49,300:INFO:_master_model_container: 1
2024-11-07 23:07:49,300:INFO:_display_container: 2
2024-11-07 23:07:49,303:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3814, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-11-07 23:07:49,303:INFO:create_model() successfully completed......................................
2024-11-07 23:07:49,545:INFO:SubProcess create_model() end ==================================
2024-11-07 23:07:49,545:INFO:Creating metrics dataframe
2024-11-07 23:07:49,571:INFO:Initializing K Neighbors Classifier
2024-11-07 23:07:49,571:INFO:Total runtime is 0.2872223973274231 minutes
2024-11-07 23:07:49,594:INFO:SubProcess create_model() called ==================================
2024-11-07 23:07:49,595:INFO:Initializing create_model()
2024-11-07 23:07:49,595:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x787230167fd0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x78723019c5e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-07 23:07:49,595:INFO:Checking exceptions
2024-11-07 23:07:49,596:INFO:Importing libraries
2024-11-07 23:07:49,596:INFO:Copying training dataset
2024-11-07 23:07:49,613:INFO:Defining folds
2024-11-07 23:07:49,614:INFO:Declaring metric variables
2024-11-07 23:07:49,629:INFO:Importing untrained model
2024-11-07 23:07:49,646:INFO:K Neighbors Classifier Imported successfully
2024-11-07 23:07:49,679:INFO:Starting cross validation
2024-11-07 23:07:49,681:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-07 23:07:49,983:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:49,977:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:49,996:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:49,990:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:50,007:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:50,011:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:50,237:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:50,255:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:50,265:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:50,352:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:50,359:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:50,374:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:50,513:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:50,520:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:50,527:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:50,722:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:50,731:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:50,753:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:50,864:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:50,882:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:50,897:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:51,068:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:51,077:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:51,085:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:51,200:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:51,218:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:51,235:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:51,355:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:51,362:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:51,369:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:51,382:INFO:Calculating mean and std
2024-11-07 23:07:51,386:INFO:Creating metrics dataframe
2024-11-07 23:07:51,392:INFO:Uploading results into container
2024-11-07 23:07:51,397:INFO:Uploading model into container now
2024-11-07 23:07:51,397:INFO:_master_model_container: 2
2024-11-07 23:07:51,397:INFO:_display_container: 2
2024-11-07 23:07:51,398:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-11-07 23:07:51,398:INFO:create_model() successfully completed......................................
2024-11-07 23:07:51,601:INFO:SubProcess create_model() end ==================================
2024-11-07 23:07:51,601:INFO:Creating metrics dataframe
2024-11-07 23:07:51,615:INFO:Initializing Naive Bayes
2024-11-07 23:07:51,615:INFO:Total runtime is 0.32129007975260415 minutes
2024-11-07 23:07:51,629:INFO:SubProcess create_model() called ==================================
2024-11-07 23:07:51,630:INFO:Initializing create_model()
2024-11-07 23:07:51,630:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x787230167fd0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x78723019c5e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-07 23:07:51,630:INFO:Checking exceptions
2024-11-07 23:07:51,630:INFO:Importing libraries
2024-11-07 23:07:51,630:INFO:Copying training dataset
2024-11-07 23:07:51,643:INFO:Defining folds
2024-11-07 23:07:51,643:INFO:Declaring metric variables
2024-11-07 23:07:51,659:INFO:Importing untrained model
2024-11-07 23:07:51,678:INFO:Naive Bayes Imported successfully
2024-11-07 23:07:51,712:INFO:Starting cross validation
2024-11-07 23:07:51,715:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-07 23:07:51,989:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:51,993:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:52,001:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:52,006:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:52,014:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:52,021:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:52,297:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:52,301:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:52,307:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:52,315:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:52,325:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:52,329:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:52,619:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:52,626:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:52,636:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:52,643:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:52,646:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:52,653:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:52,938:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:52,942:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:52,948:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:52,956:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:52,966:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:52,970:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:53,273:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:53,277:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:53,290:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:53,296:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:53,304:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:53,311:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:53,341:INFO:Calculating mean and std
2024-11-07 23:07:53,344:INFO:Creating metrics dataframe
2024-11-07 23:07:53,347:INFO:Uploading results into container
2024-11-07 23:07:53,348:INFO:Uploading model into container now
2024-11-07 23:07:53,351:INFO:_master_model_container: 3
2024-11-07 23:07:53,351:INFO:_display_container: 2
2024-11-07 23:07:53,351:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-11-07 23:07:53,352:INFO:create_model() successfully completed......................................
2024-11-07 23:07:53,516:INFO:SubProcess create_model() end ==================================
2024-11-07 23:07:53,517:INFO:Creating metrics dataframe
2024-11-07 23:07:53,529:INFO:Initializing Decision Tree Classifier
2024-11-07 23:07:53,530:INFO:Total runtime is 0.3531971176465352 minutes
2024-11-07 23:07:53,544:INFO:SubProcess create_model() called ==================================
2024-11-07 23:07:53,544:INFO:Initializing create_model()
2024-11-07 23:07:53,545:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x787230167fd0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x78723019c5e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-07 23:07:53,545:INFO:Checking exceptions
2024-11-07 23:07:53,545:INFO:Importing libraries
2024-11-07 23:07:53,545:INFO:Copying training dataset
2024-11-07 23:07:53,555:INFO:Defining folds
2024-11-07 23:07:53,557:INFO:Declaring metric variables
2024-11-07 23:07:53,573:INFO:Importing untrained model
2024-11-07 23:07:53,592:INFO:Decision Tree Classifier Imported successfully
2024-11-07 23:07:53,619:INFO:Starting cross validation
2024-11-07 23:07:53,621:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-07 23:07:53,772:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:53,779:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:53,782:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:53,786:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:53,788:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:53,795:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:53,950:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:53,958:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:53,965:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:53,966:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:53,973:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:53,981:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:54,109:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:54,118:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:54,121:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:54,128:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:54,132:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:54,139:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:54,259:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:54,266:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:54,273:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:54,274:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:54,280:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:54,288:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:54,415:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:54,420:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:54,423:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:54,428:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:54,431:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:54,434:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:54,455:INFO:Calculating mean and std
2024-11-07 23:07:54,457:INFO:Creating metrics dataframe
2024-11-07 23:07:54,462:INFO:Uploading results into container
2024-11-07 23:07:54,464:INFO:Uploading model into container now
2024-11-07 23:07:54,466:INFO:_master_model_container: 4
2024-11-07 23:07:54,466:INFO:_display_container: 2
2024-11-07 23:07:54,467:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=3814, splitter='best')
2024-11-07 23:07:54,467:INFO:create_model() successfully completed......................................
2024-11-07 23:07:54,636:INFO:SubProcess create_model() end ==================================
2024-11-07 23:07:54,636:INFO:Creating metrics dataframe
2024-11-07 23:07:54,648:INFO:Initializing SVM - Linear Kernel
2024-11-07 23:07:54,648:INFO:Total runtime is 0.3718419551849365 minutes
2024-11-07 23:07:54,661:INFO:SubProcess create_model() called ==================================
2024-11-07 23:07:54,662:INFO:Initializing create_model()
2024-11-07 23:07:54,662:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x787230167fd0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x78723019c5e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-07 23:07:54,662:INFO:Checking exceptions
2024-11-07 23:07:54,662:INFO:Importing libraries
2024-11-07 23:07:54,662:INFO:Copying training dataset
2024-11-07 23:07:54,673:INFO:Defining folds
2024-11-07 23:07:54,673:INFO:Declaring metric variables
2024-11-07 23:07:54,690:INFO:Importing untrained model
2024-11-07 23:07:54,705:INFO:SVM - Linear Kernel Imported successfully
2024-11-07 23:07:54,731:INFO:Starting cross validation
2024-11-07 23:07:54,733:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-07 23:07:54,970:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:07:54,973:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:54,977:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:07:54,980:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:54,980:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:54,983:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-07 23:07:54,987:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:54,987:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:54,990:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-07 23:07:54,994:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:55,199:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:07:55,200:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:07:55,203:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:55,203:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:55,210:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:55,210:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:55,213:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-07 23:07:55,214:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-07 23:07:55,218:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:55,218:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:55,422:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:07:55,425:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:55,432:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:55,435:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-07 23:07:55,439:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:55,451:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:07:55,454:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:55,461:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:55,464:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-07 23:07:55,467:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:55,642:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:07:55,645:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:55,651:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:55,653:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-07 23:07:55,655:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:55,694:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:07:55,698:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:55,704:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:55,708:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-07 23:07:55,712:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:55,841:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:07:55,844:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:55,850:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:55,853:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-07 23:07:55,856:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:55,914:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:07:55,917:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:55,922:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:55,925:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-07 23:07:55,927:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:55,942:INFO:Calculating mean and std
2024-11-07 23:07:55,944:INFO:Creating metrics dataframe
2024-11-07 23:07:55,947:INFO:Uploading results into container
2024-11-07 23:07:55,948:INFO:Uploading model into container now
2024-11-07 23:07:55,950:INFO:_master_model_container: 5
2024-11-07 23:07:55,950:INFO:_display_container: 2
2024-11-07 23:07:55,951:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=3814, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-11-07 23:07:55,951:INFO:create_model() successfully completed......................................
2024-11-07 23:07:56,113:INFO:SubProcess create_model() end ==================================
2024-11-07 23:07:56,113:INFO:Creating metrics dataframe
2024-11-07 23:07:56,124:INFO:Initializing Ridge Classifier
2024-11-07 23:07:56,125:INFO:Total runtime is 0.39644471009572346 minutes
2024-11-07 23:07:56,138:INFO:SubProcess create_model() called ==================================
2024-11-07 23:07:56,139:INFO:Initializing create_model()
2024-11-07 23:07:56,139:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x787230167fd0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x78723019c5e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-07 23:07:56,139:INFO:Checking exceptions
2024-11-07 23:07:56,139:INFO:Importing libraries
2024-11-07 23:07:56,139:INFO:Copying training dataset
2024-11-07 23:07:56,149:INFO:Defining folds
2024-11-07 23:07:56,150:INFO:Declaring metric variables
2024-11-07 23:07:56,165:INFO:Importing untrained model
2024-11-07 23:07:56,177:INFO:Ridge Classifier Imported successfully
2024-11-07 23:07:56,201:INFO:Starting cross validation
2024-11-07 23:07:56,205:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-07 23:07:56,317:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:07:56,321:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:56,329:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:07:56,332:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:56,336:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-07 23:07:56,337:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:56,339:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:56,357:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:56,364:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-07 23:07:56,376:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:56,466:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:07:56,470:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:56,478:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:07:56,480:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:56,482:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:56,483:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-07 23:07:56,488:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:56,489:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:56,493:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-07 23:07:56,497:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:56,604:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:07:56,607:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:56,615:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:56,618:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-07 23:07:56,622:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:56,633:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:07:56,636:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:56,643:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:56,646:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-07 23:07:56,650:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:56,719:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:07:56,723:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:56,730:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:56,733:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-07 23:07:56,737:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:56,747:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:07:56,754:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:56,762:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:56,766:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-07 23:07:56,770:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:56,844:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:07:56,847:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:56,855:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:56,858:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-07 23:07:56,862:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:56,870:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:07:56,874:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:56,878:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:56,880:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-07 23:07:56,882:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:56,900:INFO:Calculating mean and std
2024-11-07 23:07:56,902:INFO:Creating metrics dataframe
2024-11-07 23:07:56,906:INFO:Uploading results into container
2024-11-07 23:07:56,914:INFO:Uploading model into container now
2024-11-07 23:07:56,915:INFO:_master_model_container: 6
2024-11-07 23:07:56,915:INFO:_display_container: 2
2024-11-07 23:07:56,915:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=3814, solver='auto',
                tol=0.0001)
2024-11-07 23:07:56,916:INFO:create_model() successfully completed......................................
2024-11-07 23:07:57,081:INFO:SubProcess create_model() end ==================================
2024-11-07 23:07:57,081:INFO:Creating metrics dataframe
2024-11-07 23:07:57,092:INFO:Initializing Random Forest Classifier
2024-11-07 23:07:57,092:INFO:Total runtime is 0.41257575352986653 minutes
2024-11-07 23:07:57,104:INFO:SubProcess create_model() called ==================================
2024-11-07 23:07:57,105:INFO:Initializing create_model()
2024-11-07 23:07:57,105:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x787230167fd0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x78723019c5e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-07 23:07:57,105:INFO:Checking exceptions
2024-11-07 23:07:57,106:INFO:Importing libraries
2024-11-07 23:07:57,106:INFO:Copying training dataset
2024-11-07 23:07:57,115:INFO:Defining folds
2024-11-07 23:07:57,115:INFO:Declaring metric variables
2024-11-07 23:07:57,129:INFO:Importing untrained model
2024-11-07 23:07:57,148:INFO:Random Forest Classifier Imported successfully
2024-11-07 23:07:57,171:INFO:Starting cross validation
2024-11-07 23:07:57,174:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-07 23:07:57,981:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:57,989:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:57,996:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:58,003:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:58,010:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:58,018:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:58,773:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:58,777:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:58,782:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:58,816:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:58,823:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:58,830:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:59,566:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:59,571:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:59,577:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:59,612:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:59,619:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:07:59,626:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:00,370:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:00,373:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:00,377:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:00,380:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:00,384:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:00,387:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:01,126:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:01,131:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:01,138:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:01,156:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:01,160:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:01,164:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:01,173:INFO:Calculating mean and std
2024-11-07 23:08:01,175:INFO:Creating metrics dataframe
2024-11-07 23:08:01,184:INFO:Uploading results into container
2024-11-07 23:08:01,185:INFO:Uploading model into container now
2024-11-07 23:08:01,186:INFO:_master_model_container: 7
2024-11-07 23:08:01,186:INFO:_display_container: 2
2024-11-07 23:08:01,187:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=3814, verbose=0,
                       warm_start=False)
2024-11-07 23:08:01,187:INFO:create_model() successfully completed......................................
2024-11-07 23:08:01,352:INFO:SubProcess create_model() end ==================================
2024-11-07 23:08:01,352:INFO:Creating metrics dataframe
2024-11-07 23:08:01,364:INFO:Initializing Quadratic Discriminant Analysis
2024-11-07 23:08:01,364:INFO:Total runtime is 0.4837748010953267 minutes
2024-11-07 23:08:01,377:INFO:SubProcess create_model() called ==================================
2024-11-07 23:08:01,378:INFO:Initializing create_model()
2024-11-07 23:08:01,379:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x787230167fd0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x78723019c5e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-07 23:08:01,379:INFO:Checking exceptions
2024-11-07 23:08:01,379:INFO:Importing libraries
2024-11-07 23:08:01,379:INFO:Copying training dataset
2024-11-07 23:08:01,389:INFO:Defining folds
2024-11-07 23:08:01,390:INFO:Declaring metric variables
2024-11-07 23:08:01,405:INFO:Importing untrained model
2024-11-07 23:08:01,418:INFO:Quadratic Discriminant Analysis Imported successfully
2024-11-07 23:08:01,445:INFO:Starting cross validation
2024-11-07 23:08:01,448:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-07 23:08:01,596:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:08:01,600:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:01,607:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:01,621:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:01,627:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:08:01,631:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:01,638:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:01,654:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:01,736:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:08:01,739:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:01,746:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:01,753:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:01,761:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:08:01,764:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:01,774:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:01,781:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:01,864:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:08:01,868:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:01,875:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:01,882:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:01,889:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:08:01,892:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:01,898:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:01,905:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:01,988:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:08:01,992:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:01,999:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:02,006:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:02,007:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:08:02,010:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:02,017:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:02,036:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:02,134:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:08:02,138:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:02,143:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:08:02,144:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:02,146:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:02,151:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:02,153:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:02,160:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:02,170:INFO:Calculating mean and std
2024-11-07 23:08:02,172:INFO:Creating metrics dataframe
2024-11-07 23:08:02,177:INFO:Uploading results into container
2024-11-07 23:08:02,178:INFO:Uploading model into container now
2024-11-07 23:08:02,179:INFO:_master_model_container: 8
2024-11-07 23:08:02,179:INFO:_display_container: 2
2024-11-07 23:08:02,179:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-11-07 23:08:02,179:INFO:create_model() successfully completed......................................
2024-11-07 23:08:02,339:INFO:SubProcess create_model() end ==================================
2024-11-07 23:08:02,340:INFO:Creating metrics dataframe
2024-11-07 23:08:02,354:INFO:Initializing Ada Boost Classifier
2024-11-07 23:08:02,354:INFO:Total runtime is 0.5002711812655131 minutes
2024-11-07 23:08:02,366:INFO:SubProcess create_model() called ==================================
2024-11-07 23:08:02,367:INFO:Initializing create_model()
2024-11-07 23:08:02,367:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x787230167fd0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x78723019c5e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-07 23:08:02,367:INFO:Checking exceptions
2024-11-07 23:08:02,369:INFO:Importing libraries
2024-11-07 23:08:02,369:INFO:Copying training dataset
2024-11-07 23:08:02,377:INFO:Defining folds
2024-11-07 23:08:02,378:INFO:Declaring metric variables
2024-11-07 23:08:02,398:INFO:Importing untrained model
2024-11-07 23:08:02,410:INFO:Ada Boost Classifier Imported successfully
2024-11-07 23:08:02,433:INFO:Starting cross validation
2024-11-07 23:08:02,435:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-07 23:08:02,505:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-07 23:08:02,505:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-07 23:08:02,911:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:08:02,915:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:02,925:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:02,929:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-07 23:08:02,933:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:02,938:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:08:02,941:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:02,948:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:02,954:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-07 23:08:02,958:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:02,999:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-07 23:08:03,021:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-07 23:08:03,456:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:08:03,460:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:03,474:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:03,477:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-07 23:08:03,486:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:03,508:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:08:03,520:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:03,533:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:03,543:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-07 23:08:03,554:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:03,594:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-07 23:08:03,664:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-07 23:08:04,156:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:08:04,159:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:04,178:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:04,181:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-07 23:08:04,190:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:04,312:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-07 23:08:04,425:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:08:04,435:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:04,441:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:04,454:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-07 23:08:04,457:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:04,581:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-07 23:08:05,152:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:08:05,165:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:05,179:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:05,182:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-07 23:08:05,194:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:05,314:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-07 23:08:05,362:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:08:05,365:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:05,378:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:05,385:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-07 23:08:05,392:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:05,520:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-07 23:08:05,957:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:08:05,961:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:05,971:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:05,982:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-07 23:08:05,986:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:06,099:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:08:06,102:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:06,108:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:06,111:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-07 23:08:06,115:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:06,128:INFO:Calculating mean and std
2024-11-07 23:08:06,134:INFO:Creating metrics dataframe
2024-11-07 23:08:06,142:INFO:Uploading results into container
2024-11-07 23:08:06,143:INFO:Uploading model into container now
2024-11-07 23:08:06,145:INFO:_master_model_container: 9
2024-11-07 23:08:06,146:INFO:_display_container: 2
2024-11-07 23:08:06,147:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=3814)
2024-11-07 23:08:06,147:INFO:create_model() successfully completed......................................
2024-11-07 23:08:06,368:INFO:SubProcess create_model() end ==================================
2024-11-07 23:08:06,368:INFO:Creating metrics dataframe
2024-11-07 23:08:06,391:INFO:Initializing Gradient Boosting Classifier
2024-11-07 23:08:06,391:INFO:Total runtime is 0.5675483266512552 minutes
2024-11-07 23:08:06,413:INFO:SubProcess create_model() called ==================================
2024-11-07 23:08:06,413:INFO:Initializing create_model()
2024-11-07 23:08:06,413:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x787230167fd0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x78723019c5e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-07 23:08:06,413:INFO:Checking exceptions
2024-11-07 23:08:06,413:INFO:Importing libraries
2024-11-07 23:08:06,414:INFO:Copying training dataset
2024-11-07 23:08:06,424:INFO:Defining folds
2024-11-07 23:08:06,428:INFO:Declaring metric variables
2024-11-07 23:08:06,449:INFO:Importing untrained model
2024-11-07 23:08:06,466:INFO:Gradient Boosting Classifier Imported successfully
2024-11-07 23:08:06,499:INFO:Starting cross validation
2024-11-07 23:08:06,501:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-07 23:08:25,505:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:08:25,509:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:25,515:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:25,522:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:25,649:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:08:25,653:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:25,659:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:25,666:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:43,286:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:08:43,290:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:43,296:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:43,303:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:44,086:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:08:44,099:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:44,107:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:08:44,113:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:02,874:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:09:02,878:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:02,886:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:02,893:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:03,413:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:09:03,417:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:03,425:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:03,432:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:21,331:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:09:21,334:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:21,341:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:21,347:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:21,778:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:09:21,782:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:21,788:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:21,795:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:39,246:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:09:39,249:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:39,256:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:39,263:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:39,635:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:09:39,637:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:39,641:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:39,645:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:39,658:INFO:Calculating mean and std
2024-11-07 23:09:39,660:INFO:Creating metrics dataframe
2024-11-07 23:09:39,667:INFO:Uploading results into container
2024-11-07 23:09:39,669:INFO:Uploading model into container now
2024-11-07 23:09:39,669:INFO:_master_model_container: 10
2024-11-07 23:09:39,669:INFO:_display_container: 2
2024-11-07 23:09:39,670:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3814, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-11-07 23:09:39,670:INFO:create_model() successfully completed......................................
2024-11-07 23:09:39,844:INFO:SubProcess create_model() end ==================================
2024-11-07 23:09:39,845:INFO:Creating metrics dataframe
2024-11-07 23:09:39,858:INFO:Initializing Linear Discriminant Analysis
2024-11-07 23:09:39,859:INFO:Total runtime is 2.125344395637512 minutes
2024-11-07 23:09:39,872:INFO:SubProcess create_model() called ==================================
2024-11-07 23:09:39,873:INFO:Initializing create_model()
2024-11-07 23:09:39,873:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x787230167fd0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x78723019c5e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-07 23:09:39,873:INFO:Checking exceptions
2024-11-07 23:09:39,873:INFO:Importing libraries
2024-11-07 23:09:39,873:INFO:Copying training dataset
2024-11-07 23:09:39,882:INFO:Defining folds
2024-11-07 23:09:39,883:INFO:Declaring metric variables
2024-11-07 23:09:39,897:INFO:Importing untrained model
2024-11-07 23:09:39,913:INFO:Linear Discriminant Analysis Imported successfully
2024-11-07 23:09:39,945:INFO:Starting cross validation
2024-11-07 23:09:39,947:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-07 23:09:40,062:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:09:40,065:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:40,072:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:40,074:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:09:40,077:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:40,079:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:40,095:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:40,108:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:40,248:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:09:40,254:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:40,276:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:40,283:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:09:40,286:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:40,290:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:40,293:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:40,299:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:40,407:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:09:40,411:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:40,427:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:40,444:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:40,497:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:09:40,506:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:40,521:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:40,548:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:40,612:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:09:40,617:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:40,626:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:40,633:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:40,765:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:09:40,772:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:40,788:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:40,795:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:40,803:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:09:40,806:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:40,824:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:40,840:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:40,913:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-07 23:09:40,917:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:40,923:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:40,929:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:40,943:INFO:Calculating mean and std
2024-11-07 23:09:40,945:INFO:Creating metrics dataframe
2024-11-07 23:09:40,951:INFO:Uploading results into container
2024-11-07 23:09:40,955:INFO:Uploading model into container now
2024-11-07 23:09:40,956:INFO:_master_model_container: 11
2024-11-07 23:09:40,956:INFO:_display_container: 2
2024-11-07 23:09:40,957:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-11-07 23:09:40,957:INFO:create_model() successfully completed......................................
2024-11-07 23:09:41,167:INFO:SubProcess create_model() end ==================================
2024-11-07 23:09:41,167:INFO:Creating metrics dataframe
2024-11-07 23:09:41,185:INFO:Initializing Extra Trees Classifier
2024-11-07 23:09:41,186:INFO:Total runtime is 2.147461720307668 minutes
2024-11-07 23:09:41,202:INFO:SubProcess create_model() called ==================================
2024-11-07 23:09:41,203:INFO:Initializing create_model()
2024-11-07 23:09:41,203:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x787230167fd0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x78723019c5e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-07 23:09:41,203:INFO:Checking exceptions
2024-11-07 23:09:41,209:INFO:Importing libraries
2024-11-07 23:09:41,209:INFO:Copying training dataset
2024-11-07 23:09:41,223:INFO:Defining folds
2024-11-07 23:09:41,223:INFO:Declaring metric variables
2024-11-07 23:09:41,236:INFO:Importing untrained model
2024-11-07 23:09:41,250:INFO:Extra Trees Classifier Imported successfully
2024-11-07 23:09:41,281:INFO:Starting cross validation
2024-11-07 23:09:41,283:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-07 23:09:42,226:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:42,234:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:42,246:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:42,278:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:42,291:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:42,312:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:43,160:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:43,175:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:43,201:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:43,269:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:43,277:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:43,291:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:44,328:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:44,353:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:44,355:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:44,367:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:44,369:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:44,381:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:45,446:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:45,460:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:45,476:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:45,494:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:45,515:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:45,529:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:46,296:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:46,303:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:46,310:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:46,323:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:46,332:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:46,338:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:46,347:INFO:Calculating mean and std
2024-11-07 23:09:46,349:INFO:Creating metrics dataframe
2024-11-07 23:09:46,356:INFO:Uploading results into container
2024-11-07 23:09:46,357:INFO:Uploading model into container now
2024-11-07 23:09:46,357:INFO:_master_model_container: 12
2024-11-07 23:09:46,358:INFO:_display_container: 2
2024-11-07 23:09:46,358:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=3814, verbose=0,
                     warm_start=False)
2024-11-07 23:09:46,358:INFO:create_model() successfully completed......................................
2024-11-07 23:09:46,521:INFO:SubProcess create_model() end ==================================
2024-11-07 23:09:46,521:INFO:Creating metrics dataframe
2024-11-07 23:09:46,541:INFO:Initializing Extreme Gradient Boosting
2024-11-07 23:09:46,542:INFO:Total runtime is 2.236727790037791 minutes
2024-11-07 23:09:46,560:INFO:SubProcess create_model() called ==================================
2024-11-07 23:09:46,561:INFO:Initializing create_model()
2024-11-07 23:09:46,561:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x787230167fd0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x78723019c5e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-07 23:09:46,561:INFO:Checking exceptions
2024-11-07 23:09:46,561:INFO:Importing libraries
2024-11-07 23:09:46,561:INFO:Copying training dataset
2024-11-07 23:09:46,571:INFO:Defining folds
2024-11-07 23:09:46,572:INFO:Declaring metric variables
2024-11-07 23:09:46,584:INFO:Importing untrained model
2024-11-07 23:09:46,598:INFO:Extreme Gradient Boosting Imported successfully
2024-11-07 23:09:46,623:INFO:Starting cross validation
2024-11-07 23:09:46,625:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-07 23:09:47,461:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:47,469:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:47,478:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:47,509:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:47,516:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:47,524:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:48,206:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:48,213:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:48,220:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:48,243:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:48,250:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:48,257:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:48,985:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:48,992:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:48,999:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:49,000:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:49,007:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:49,014:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:49,742:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:49,750:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:49,758:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:49,774:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:49,781:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:49,788:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:50,482:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:50,490:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:50,504:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:50,509:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:50,519:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:50,526:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:09:50,543:INFO:Calculating mean and std
2024-11-07 23:09:50,548:INFO:Creating metrics dataframe
2024-11-07 23:09:50,555:INFO:Uploading results into container
2024-11-07 23:09:50,557:INFO:Uploading model into container now
2024-11-07 23:09:50,558:INFO:_master_model_container: 13
2024-11-07 23:09:50,558:INFO:_display_container: 2
2024-11-07 23:09:50,559:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-11-07 23:09:50,559:INFO:create_model() successfully completed......................................
2024-11-07 23:09:50,718:INFO:SubProcess create_model() end ==================================
2024-11-07 23:09:50,718:INFO:Creating metrics dataframe
2024-11-07 23:09:50,731:INFO:Initializing Light Gradient Boosting Machine
2024-11-07 23:09:50,732:INFO:Total runtime is 2.3065677642822267 minutes
2024-11-07 23:09:50,745:INFO:SubProcess create_model() called ==================================
2024-11-07 23:09:50,746:INFO:Initializing create_model()
2024-11-07 23:09:50,746:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x787230167fd0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x78723019c5e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-07 23:09:50,746:INFO:Checking exceptions
2024-11-07 23:09:50,746:INFO:Importing libraries
2024-11-07 23:09:50,746:INFO:Copying training dataset
2024-11-07 23:09:50,756:INFO:Defining folds
2024-11-07 23:09:50,757:INFO:Declaring metric variables
2024-11-07 23:09:50,769:INFO:Importing untrained model
2024-11-07 23:09:50,785:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-07 23:09:50,814:INFO:Starting cross validation
2024-11-07 23:09:50,816:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-07 23:10:05,335:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:10:05,343:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:10:05,352:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:10:05,411:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:10:05,418:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:10:05,426:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:10:32,726:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:10:32,734:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:10:32,742:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:10:32,752:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:10:32,759:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:10:32,766:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:10:39,863:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:10:39,870:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:10:39,877:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:10:40,278:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:10:40,283:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:10:40,288:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:10:53,539:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:10:53,545:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:10:53,552:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:10:53,931:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:10:53,936:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:10:53,942:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:11:04,931:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:11:04,938:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:11:04,946:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:11:05,275:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:11:05,280:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:11:05,284:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:11:05,295:INFO:Calculating mean and std
2024-11-07 23:11:05,299:INFO:Creating metrics dataframe
2024-11-07 23:11:05,305:INFO:Uploading results into container
2024-11-07 23:11:05,306:INFO:Uploading model into container now
2024-11-07 23:11:05,307:INFO:_master_model_container: 14
2024-11-07 23:11:05,307:INFO:_display_container: 2
2024-11-07 23:11:05,307:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3814, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-11-07 23:11:05,308:INFO:create_model() successfully completed......................................
2024-11-07 23:11:05,484:INFO:SubProcess create_model() end ==================================
2024-11-07 23:11:05,484:INFO:Creating metrics dataframe
2024-11-07 23:11:05,504:INFO:Initializing Dummy Classifier
2024-11-07 23:11:05,504:INFO:Total runtime is 3.5527748584747316 minutes
2024-11-07 23:11:05,521:INFO:SubProcess create_model() called ==================================
2024-11-07 23:11:05,522:INFO:Initializing create_model()
2024-11-07 23:11:05,522:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x787230167fd0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x78723019c5e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-07 23:11:05,522:INFO:Checking exceptions
2024-11-07 23:11:05,522:INFO:Importing libraries
2024-11-07 23:11:05,522:INFO:Copying training dataset
2024-11-07 23:11:05,533:INFO:Defining folds
2024-11-07 23:11:05,534:INFO:Declaring metric variables
2024-11-07 23:11:05,552:INFO:Importing untrained model
2024-11-07 23:11:05,569:INFO:Dummy Classifier Imported successfully
2024-11-07 23:11:05,610:INFO:Starting cross validation
2024-11-07 23:11:05,612:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-07 23:11:05,758:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:11:05,758:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:11:05,765:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:11:05,765:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:11:05,768:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-07 23:11:05,768:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-07 23:11:05,772:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:11:05,772:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:11:05,902:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:11:05,905:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:11:05,910:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:11:05,912:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:11:05,914:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-07 23:11:05,915:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-07 23:11:05,918:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:11:05,919:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:11:06,042:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:11:06,048:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:11:06,049:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:11:06,052:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-07 23:11:06,054:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:11:06,056:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:11:06,058:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-07 23:11:06,062:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:11:06,171:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:11:06,178:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:11:06,181:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:11:06,182:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-07 23:11:06,185:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:11:06,188:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:11:06,192:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-07 23:11:06,196:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:11:06,307:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:11:06,314:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:11:06,314:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:11:06,317:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-07 23:11:06,321:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:11:06,321:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:11:06,324:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-07 23:11:06,328:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'Watermelon') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-07 23:11:06,345:INFO:Calculating mean and std
2024-11-07 23:11:06,347:INFO:Creating metrics dataframe
2024-11-07 23:11:06,356:INFO:Uploading results into container
2024-11-07 23:11:06,357:INFO:Uploading model into container now
2024-11-07 23:11:06,358:INFO:_master_model_container: 15
2024-11-07 23:11:06,358:INFO:_display_container: 2
2024-11-07 23:11:06,358:INFO:DummyClassifier(constant=None, random_state=3814, strategy='prior')
2024-11-07 23:11:06,358:INFO:create_model() successfully completed......................................
2024-11-07 23:11:06,519:INFO:SubProcess create_model() end ==================================
2024-11-07 23:11:06,519:INFO:Creating metrics dataframe
2024-11-07 23:11:06,541:WARNING:/usr/local/lib/python3.10/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-11-07 23:11:06,581:INFO:Initializing create_model()
2024-11-07 23:11:06,581:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x787230167fd0>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=3814, verbose=0,
                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-07 23:11:06,582:INFO:Checking exceptions
2024-11-07 23:11:06,586:INFO:Importing libraries
2024-11-07 23:11:06,586:INFO:Copying training dataset
2024-11-07 23:11:06,593:INFO:Defining folds
2024-11-07 23:11:06,594:INFO:Declaring metric variables
2024-11-07 23:11:06,594:INFO:Importing untrained model
2024-11-07 23:11:06,594:INFO:Declaring custom model
2024-11-07 23:11:06,595:INFO:Extra Trees Classifier Imported successfully
2024-11-07 23:11:06,596:INFO:Cross validation set to False
2024-11-07 23:11:06,597:INFO:Fitting Model
2024-11-07 23:11:06,624:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2024-11-07 23:11:06,871:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=3814, verbose=0,
                     warm_start=False)
2024-11-07 23:11:06,871:INFO:create_model() successfully completed......................................
2024-11-07 23:11:07,079:INFO:_master_model_container: 15
2024-11-07 23:11:07,079:INFO:_display_container: 2
2024-11-07 23:11:07,080:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=3814, verbose=0,
                     warm_start=False)
2024-11-07 23:11:07,080:INFO:compare_models() successfully completed......................................
2024-11-07 23:11:16,224:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-07 23:11:53,348:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-07 23:11:53,357:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-07 23:11:53,360:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-07 23:11:58,024:WARNING:/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

